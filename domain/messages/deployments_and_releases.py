def build_deployments_and_releases_prompt(few_shot=None, additional_messages=None):
    """
    Build a message prompt for the LLM that instructs it to parse the Octopus HCL context and the JSON blob with releases.
    :param few_shot: Additional user messages providing a few shot example.
    :return: The messages to pass to the llm.
    """

    if few_shot is None:
        few_shot = []

    if additional_messages is None:
        additional_messages = []

    # Some of the prompts come from https://arxiv.org/pdf/2312.16171.pdf
    messages = [
        ("system", "You are a concise and helpful agent."),
        (
            "system",
            "Projects, environments, channels, and tenants, and spaces are provided in the HCL context.",
        ),
        (
            "system",
            'Deployments and releases are provided in the "Deployments" property in the JSON context.',
        ),
        (
            "system",
            "You must link the deployments in the JSON context to the projects, environments, channels, tenants, and space in the HCL context.",
        ),
        # The LLM was confused when it saw release versions that were not traditional semver type versions.
        # For example, the tests used to create guids for release versions to ensure the results matched the
        # newly created releases, and the response was often something like "The JSON does not contain
        # information about releases." Switching to calver style release versions fixed the tests.
        (
            "system",
            'The "ReleaseVersion" field in the JSON context contains the version of the release.',
        ),
        ("system", "Release versions can be any string."),
        (
            "system",
            "You will be penalized for assuming release versions must be numbers.",
        ),
        # Tests were failing because the LLM reported the HCL didn't contain information about releases and deployments.
        # We need to encourage the LLM not to report that there are no deployments in the context.
        (
            "system",
            "You will be penalized for responding that the HCL context does not contain information about deployments or releases.",
        ),
        (
            "system",
            "You will be penalized for responding that the JSON context does not contain information about deployments or releases.",
        ),
        # The LLM would often complain that it didn't know the relative order of deployments
        (
            "system",
            'The "Created" field in the items in the JSON array defines when a deployment was initiated to the associated environment and channel.',
        ),
        # The LLM will often answer "Based on the provided HCL and JSON context, the answer is ...".
        # This is not useful information for the end user.
        (
            "system",
            "You will be penalized for mentioning that the answer was based on the HCL or JSON context",
        ),
        (
            "system",
            'You will be penalized for including phrases like "Based on the HCL" or "Based on the JSON" in the answer',
        ),
        # Prompts like "List the description of a tenant" or "Find the tags associated with a tenant"
        # resulted in the LLM providing instructions on how to find the information rather than presenting
        # the answer. Here we instruct the LLM to provide the answer directly.
        (
            "system",
            "You must provide an answer to the question based on the data in the supplied JSON and HCL context.",
        ),
        (
            "system",
            "You will be penalized for providing instructions on how to find the answer.",
        ),
        ("system", "You will be penalized for providing a code sample as the answer."),
        # The LLM would often fail completely if it encountered an empty or missing attribute. These instructions
        # guide the LLM to provide as much information as possible in the answer, and not treat missing
        # information as an error.
        (
            "system",
            "Your answer must include any information you found in the context relevant to the question.",
        ),
        (
            "system",
            "Your answer must clearly state if the supplied context does not provide the requested information.",
        ),
        (
            "system",
            "You must provide a response even if the context does not provide some of the requested information.",
        ),
        (
            "system",
            "It is ok if you can not find most of the requested information in the context - "
            + "just provide what you can find.",
        ),
        ("system", "Iâ€™m going to tip $500 for a better solution!"),
        *few_shot,
        ("user", "Question: {input}"),
        *additional_messages,
        # https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-the-openai-api
        # Put instructions at the beginning of the prompt and use ### or """ to separate the instruction and context
        ("user", "JSON: ###\n{json}\n###"),
        ("user", "HCL: ###\n{hcl}\n###"),
        ("user", "Answer:"),
    ]

    return messages
